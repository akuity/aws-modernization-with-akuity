---
AWSTemplateFormatVersion: '2010-09-09'
Description: Cloudformation template for Akuity and AWS Modernization Workshop
Parameters:
  KubernetesVersion:
    Description: Kubernetes version
    Type: String
    Default: "1.31"

  EKSClusterName:
    Description: Name of EKS Cluster
    Type: String
    Default: "akuity-aws-cluster"

  WorkerNodeInstanceType:
    Description: Worker Node cluster instances
    Type: String
    Default: "t3.large"
    
  VSCodeInstanceName:
    Description: Name of the VSCode server instance
    Type: String
    Default: "VSCodeServer"
    
  ArgocdAdminPassword:
    Description: Admin password for ArgoCD
    Type: String
    Default: "Akuity@AWS123"
    MinLength: 8
    NoEcho: true

Resources:
################## PERMISSIONS AND ROLES #################
  ClusterRole:
    Type: AWS::IAM::Role
    Properties:
      Tags:
        - Key: Environment
          Value: akuity-and-aws-workshop
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
            - ssm.amazonaws.com
            - codebuild.amazonaws.com
            AWS: !Sub arn:aws:iam::${AWS::AccountId}:root
          Action:
          - sts:AssumeRole
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/AmazonEKSClusterPolicy
      - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
      - arn:aws:iam::aws:policy/CloudWatchLogsFullAccess
      Path: "/"
      RoleName: !Sub "akuity-and-aws-workshop-admin-${AWS::StackName}"
      Policies:
        - PolicyName: EKSPermissions
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - eks:DescribeCluster
                  - eks:ListClusters
                  - eks:UpdateClusterConfig
                  - eks:TagResource
                  - eks:CreateCluster
                  - eks:DeleteCluster
                Resource: !Sub arn:aws:eks:*:*:cluster/*
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                  - elasticloadbalancing:DescribeLoadBalancers
                  - elasticloadbalancing:CreateLoadBalancer
                  - elasticloadbalancing:DeleteLoadBalancer
                  - elasticloadbalancing:DescribeTargetGroups
                  - elasticloadbalancing:CreateTargetGroup
                  - elasticloadbalancing:DeleteTargetGroup
                  - elasticloadbalancing:RegisterTargets
                  - elasticloadbalancing:DeregisterTargets
                  - iam:GetRole
                  - iam:PassRole
                  - ssm:PutParameter
                  - ssm:GetParameter
                  - ssm:DeleteParameter
                  - ec2:DescribeInstances
                  - ssm:SendCommand
                Resource: "*"

  KMSSecretsKey:
    Type: AWS::KMS::Key
    Properties:
      Description: "key for EKS secrets encryption"
      Enabled: true
      KeyPolicy:
        Version: '2012-10-17'
        Id: key-default-1
        Statement:
        - Sid: Enable IAM User Permissions
          Effect: Allow
          Principal:
            AWS: !Sub arn:aws:iam::${AWS::AccountId}:root
          Action:
            - kms:Create*
            - kms:Describe*
            - kms:Enable*
            - kms:List*
            - kms:Put*
            - kms:Update*
            - kms:Revoke*
            - kms:Disable*
            - kms:Get*
            - kms:Delete*
            - kms:ScheduleKeyDeletion
            - kms:CancelKeyDeletion
            - kms:GenerateDataKey
            - kms:Encrypt
            - kms:Decrypt
          Resource: '*'

################## INSTANCE PROFILE #####################

  WorkshopInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: "/"
      InstanceProfileName: !Sub "akuity-and-aws-workshop-admin-${AWS::StackName}"
      Roles:
      - Ref: ClusterRole

################## EKS Bootstrap #####################

  BuildProject:
    Type: AWS::CodeBuild::Project
    Properties:
      Name: !Sub CodeBuild-${AWS::StackName}
      ServiceRole: !GetAtt ClusterRole.Arn
      Artifacts:
        Type: NO_ARTIFACTS
      LogsConfig:
        CloudWatchLogs:
          Status: ENABLED
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/amazonlinux2-x86_64-standard:5.0
        EnvironmentVariables:
          - Name: CFN_RESPONSE_URL
            Value: !Ref WaitForStackCreationHandle
          - Name: WORKSHOP_INSTANCE_PROFILE_ARN
            Value: !GetAtt WorkshopInstanceProfile.Arn
          - Name: VSCodeInstanceName
            Value: !Ref VSCodeInstanceName
          - Name: KMS_ARN
            Value: !GetAtt KMSSecretsKey.Arn
          - Name: ARGOCD_PASSWORD
            Value: !Ref ArgocdAdminPassword
          - Name: EKSClusterName
            Value: !Ref EKSClusterName
          - Name: AWSRegion
            Value: !Ref AWS::Region
          - Name: STACK_NAME
            Value: ${AWS::StackName}
      Source:
        Type: NO_SOURCE
        BuildSpec:
          !Sub |
              version: 0.2
              phases:
                install:
                  runtime-versions:
                    python: 3.12
                  commands:
                    - echo ">>> installed python 3.12"
                    - yum install -y httpd-tools jq
                pre_build:
                  commands:
                    - echo ">>> build cluster config"
                    - |
                      cat <<EOF > cluster-config.yaml
                      apiVersion: eksctl.io/v1alpha5
                      kind: ClusterConfig
                      availabilityZones:
                        - ${AWS::Region}a
                        - ${AWS::Region}b
                        - ${AWS::Region}c
                      metadata:
                        name: ${EKSClusterName}
                        region: ${AWS::Region}
                        version: "${KubernetesVersion}"
                      cloudWatch:
                          clusterLogging:
                              enableTypes: ["*"]
                      secretsEncryption:
                        keyARN: $KMS_ARN
                      managedNodeGroups:
                        - name: nodegroup
                          instanceType: ${WorkerNodeInstanceType}
                          desiredCapacity: 1
                          minSize: 1
                          maxSize: 2
                          privateNetworking: true
                          volumeSize: 100
                          volumeType: gp3
                          volumeEncrypted: true
                          tags:
                            'eks:cluster-name': ${EKSClusterName}
                            'stack-name': ${AWS::StackName}
                          iam:
                            withAddonPolicies:
                              imageBuilder: true
                              autoScaler: true
                              externalDNS: true
                              certManager: true
                              appMesh: true
                              ebs: true
                              fsx: true
                              efs: true
                              albIngress: true
                              xRay: true
                              cloudWatch: true
                      EOF
                    - echo ">>> install awscli "
                    - pip3 install --upgrade --user awscli
                    - echo ">>> install kubectl"
                    - curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl
                    - chmod +x ./kubectl
                    - curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
                    - mv -v /tmp/eksctl /usr/local/bin
                    - eksctl version
                    - export PATH=$PWD/:$PATH
                build:
                  commands:
                    - echo ">>> creating EKS cluster"
                    - eksctl create cluster -f cluster-config.yaml || (echo "Failed to create EKS cluster" && exit 1)
                    - aws eks update-kubeconfig --name $EKSClusterName --region $AWSRegion
                    
                    # Install ArgoCD
                    - echo ">>> Installing ArgoCD"
                    - kubectl create namespace argocd || echo "Namespace argocd already exists"
                    - kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
                    
                    # Wait for ArgoCD to be ready
                    - echo ">>> Waiting for ArgoCD to be ready"
                    - kubectl -n argocd wait --for=condition=available deployment/argocd-server --timeout=300s || (echo "ArgoCD server deployment timed out" && exit 1)
                    
                    # Create admin password
                    - echo ">>> Setting up ArgoCD admin password"
                    - |
                      if [ -z "$ARGOCD_PASSWORD" ]; then
                        echo "No password provided, generating secure password"
                        ARGOCD_PASSWORD=$(openssl rand -base64 12)
                        echo "Generated password: $ARGOCD_PASSWORD"
                      fi
                      - kubectl -n argocd patch secret argocd-secret \
                        -p "{\"stringData\": {\"admin.password\": \"$(htpasswd -bnBC 10 \"\" $ARGOCD_PASSWORD | tr -d ':\n' | sed 's/\$2y/\$2a/')\", \"admin.passwordMtime\": \"$(date +%FT%T%Z)\"}}"
                    
                    # Configure ArgoCD server to be accessible
                    - echo ">>> Configuring ArgoCD access"
                    - |
                      kubectl patch svc argocd-server -n argocd -p '{
                        "spec": {
                          "type": "LoadBalancer"
                        }
                      }'
                    
                    # Store ArgoCD URL and credentials in SSM Parameters
                    - echo ">>> Storing ArgoCD access information"
                    - |
                      # Wait for Load Balancer to be assigned
                      counter=0
                      max_attempts=60
                      while [ $counter -lt $max_attempts ]; do
                        ARGOCD_SERVER=$(kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null)
                        if [ ! -z "$ARGOCD_SERVER" ]; then
                          echo "LoadBalancer hostname: $ARGOCD_SERVER"
                          break
                        fi
                        sleep 10
                        counter=$((counter + 1))
                        echo "Waiting for ArgoCD Load Balancer... Attempt $counter of $max_attempts"
                      done

                      if [[ -z "$ARGOCD_SERVER" ]]; then
                        echo "❌ ERROR: LoadBalancer hostname not assigned after $max_attempts attempts"
                        exit 1
                      fi
                    
                    - |
                      # Store ArgoCD access info in SSM Parameter Store with proper prefix
                      SSM_PREFIX="/eks/${EKSClusterName}-${AWS::StackName}"
                      
                      if [ ! -z "$ARGOCD_SERVER" ]; then
                        # Store ArgoCD access info in SSM Parameter Store
                        aws ssm put-parameter --name "$SSM_PREFIX/argocd-server" --value "$ARGOCD_SERVER" --type "String" --overwrite
                        aws ssm put-parameter --name "$SSM_PREFIX/argocd-username" --value "admin" --type "String" --overwrite
                        aws ssm put-parameter --name "$SSM_PREFIX/argocd-password" --value "$ARGOCD_PASSWORD" --type "SecureString" --overwrite
                        echo "ArgoCD access info stored in SSM Parameter Store under prefix $SSM_PREFIX"
                      else
                        echo "WARNING: Could not get ArgoCD Server URL - Load Balancer may still be provisioning"
                        # Proceed anyway, we'll store the fact that it's being provisioned
                        aws ssm put-parameter --name "$SSM_PREFIX/argocd-username" --value "admin" --type "String" --overwrite
                        aws ssm put-parameter --name "$SSM_PREFIX/argocd-password" --value "$ARGOCD_PASSWORD" --type "SecureString" --overwrite
                        aws ssm put-parameter --name "$SSM_PREFIX/argocd-server" --value "pending-loadbalancer-creation" --type "String" --overwrite
                      fi
                    
                    # Add setup script to VSCode server
                    - echo ">>> Setting up VSCode server with kubeconfig and ArgoCD access"
                    - |
                      VSCODE_INSTANCE_ID=$(aws ec2 describe-instances \
                        --filters "Name=tag:Name,Values=$VSCodeInstanceName" \
                        --query "Reservations[0].Instances[0].InstanceId" \
                        --output text)
                    
                      if [ -z "$VSCODE_INSTANCE_ID" ] || [ "$VSCODE_INSTANCE_ID" == "None" ]; then
                        echo "WARNING: Could not find VSCode instance with name $VSCodeInstanceName"
                      else
                        echo "Found VSCode instance: $VSCODE_INSTANCE_ID"
                        
                        # Create individual commands for VSCode setup
                        aws ssm send-command \
                          --document-name "AWS-RunShellScript" \
                          --targets "Key=instanceids,Values=$VSCODE_INSTANCE_ID" \
                          --parameters 'commands=[
                            "#!/bin/bash",
                            "# Install ArgoCD CLI",
                            "curl -sSL -o /tmp/argocd-linux-amd64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64",
                            "chmod +x /tmp/argocd-linux-amd64",
                            "mv /tmp/argocd-linux-amd64 /usr/local/bin/argocd",
                            "# Create workshop directory",
                            "mkdir -p /home/participant/workshops",
                            "# Create ArgoCD info script",
                            "cat > /home/participant/workshops/argocd-info.sh << \"EOF\"",
                            "#!/bin/bash",
                            "CLUSTER_NAME=\"'"${EKSClusterName}"'\"",
                            "STACK_NAME=\"'"${AWS::StackName}"'\"",
                            "SSM_PREFIX=\"/eks/$CLUSTER_NAME-$STACK_NAME\"",
                            "",
                            "# Get ArgoCD server URL",
                            "ARGOCD_SERVER=$(aws ssm get-parameter --name \"$SSM_PREFIX/argocd-server\" --query \"Parameter.Value\" --output text 2>/dev/null || echo \"Not available yet\")",
                            "ARGOCD_USERNAME=$(aws ssm get-parameter --name \"$SSM_PREFIX/argocd-username\" --query \"Parameter.Value\" --output text 2>/dev/null || echo \"admin\")",
                            "ARGOCD_PASSWORD=$(aws ssm get-parameter --name \"$SSM_PREFIX/argocd-password\" --with-decryption --query \"Parameter.Value\" --output text 2>/dev/null || echo \"Not available yet\")",
                            "",
                            "if [ \"$ARGOCD_SERVER\" == \"pending-loadbalancer-creation\" ] || [ \"$ARGOCD_SERVER\" == \"Not available yet\" ]; then",
                            "  echo \"ArgoCD LoadBalancer is still being provisioned...\"",
                            "  echo \"Please wait a few minutes and try again.\"",
                            "  exit 0",
                            "fi",
                            "",
                            "echo",
                            "echo \"===================================================\"",
                            "echo \"  ArgoCD is installed on your EKS cluster!\"",
                            "echo \"===================================================\"",
                            "echo \"URL: https://$ARGOCD_SERVER\"",
                            "echo \"Username: $ARGOCD_USERNAME\"",
                            "echo \"Password: $ARGOCD_PASSWORD\"",
                            "echo \"===================================================\"",
                            "echo",
                            "echo \"To access ArgoCD CLI, run:\"",
                            "echo \"  argocd login $ARGOCD_SERVER --username admin --password \\\"$ARGOCD_PASSWORD\\\" --insecure\"",
                            "echo",
                            "EOF",
                            "chmod +x /home/participant/workshops/argocd-info.sh",
                            "# Set up kubeconfig",
                            "mkdir -p /home/participant/.kube",
                            "aws eks update-kubeconfig --name \"'"${EKSClusterName}"'\" --region \"'"${AWS::Region}"'\" --kubeconfig /home/participant/.kube/config",
                            "# Add useful aliases to bashrc",
                            "cat >> /home/participant/.bashrc << \"EOF\"",
                            "# Kubernetes aliases",
                            "alias k=kubectl",
                            "alias kgp=\"kubectl get pods\"",
                            "alias kgs=\"kubectl get svc\"",
                            "alias kgd=\"kubectl get deployments\"",
                            "alias kga=\"kubectl get all\"",
                            "alias kgn=\"kubectl get nodes\"",
                            "# ArgoCD quick access",
                            "alias argocd-info=\"/home/participant/workshops/argocd-info.sh\"",
                            "EOF",
                            "echo \"echo \\\"Kubernetes and ArgoCD tools are ready!\\\"\" >> /home/participant/.bashrc",
                            "echo \"echo \\\"Run \'argocd-info\' to get ArgoCD access information\\\"\" >> /home/participant/.bashrc",
                            "# Set proper ownership",
                            "chown -R participant:participant /home/participant/workshops",
                            "chown -R participant:participant /home/participant/.kube",
                            "chmod 600 /home/participant/.kube/config",
                            "chown participant:participant /home/participant/.bashrc"
                          ]'
                      fi
                post_build:
                  commands:
                    # CODEBUILD_BUILD_SUCCEEDING = 1 Set to 0 if the build is failing, or 1 if the build is succeeding.
                    - echo ">>> build status $CODEBUILD_BUILD_SUCCEEDING "
                    - |
                      if [ "$CODEBUILD_BUILD_SUCCEEDING" -eq "1" ]; then
                        curl -X PUT -H 'Content-Type:' --data-binary '{"Status" : "SUCCESS","Reason" : "Creation Complete", "UniqueId" : "'"$CODEBUILD_BUILD_ID"'","Data" : "Creation complete"}' $CFN_RESPONSE_URL
                      else
                        curl -X PUT -H 'Content-Type:' --data-binary '{"Status" : "FAILURE","Reason" : "Creation Failed", "UniqueId" : "'"$CODEBUILD_BUILD_ID"'","Data" : "See Codebuild logs for details. '"$CODEBUILD_LOG_PATH"'"}' $CFN_RESPONSE_URL
                      fi
      TimeoutInMinutes: 60

  WaitForStackCreationHandle:
    Type: AWS::CloudFormation::WaitConditionHandle

  WaitCondition:
    Type: AWS::CloudFormation::WaitCondition
    # don't start till we create a lambda function
    DependsOn: [CustomTriggerBuild]
    Properties:
      Handle: !Ref WaitForStackCreationHandle
      # wait for 59 minutes before giving up - ensuring it's less than the CodeBuild timeout
      Timeout: "3540"
      # success or failure signal count
      Count: 1

  CustomTriggerBuild:
    Type: Custom::ManageWorkshopIamRole
    Properties:
      ServiceToken: !GetAtt TriggerBuildLambda.Arn
      CodebuildProjectName: !Ref BuildProject    


  TriggerBuildLambdaIamRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
                - codebuild.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/CloudWatchLogsFullAccess
        - arn:aws:iam::aws:policy/AWSCodeBuildAdminAccess
      Policies:
        - PolicyName: !Sub IAMPolicy-${AWS::StackName}
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                    - codebuild:*
                Resource: !GetAtt BuildProject.Arn

  TriggerBuildLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: function to trigger CodeBuild project
      Handler: index.handler
      Role: !GetAtt TriggerBuildLambdaIamRole.Arn
      Runtime: python3.12
      Timeout: 60
      Code:
        ZipFile: |
          import boto3
          import logging
          import traceback
          import json
          import urllib3

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          http = urllib3.PoolManager()

          codebuild_client = boto3.client('codebuild')

          def send_cfn_response(event, context, response_status, reason=None, response_data=None):
              response_body = {
                  'Status': response_status,
                  'Reason': reason or 'See CloudWatch logs for details',
                  'PhysicalResourceId': event.get('PhysicalResourceId', context.log_stream_name),
                  'StackId': event['StackId'],
                  'RequestId': event['RequestId'],
                  'LogicalResourceId': event['LogicalResourceId'],
                  'Data': response_data or {}
              }
              
              try:
                  http.request('PUT', event['ResponseURL'], 
                          body=json.dumps(response_body).encode('utf-8'),
                          headers={'Content-Type': 'application/json'})
                  logger.info("CFN response sent successfully")
              except Exception as e:
                  logger.error(f"Failed to send CFN response: {str(e)}")
                  logger.error(traceback.format_exc())

          def handler(event, context):
              logger.info(f'Incoming Event: {event}')
              
              try:
                  if event['RequestType'] == 'Delete':
                      logger.info(f'Nothing to do. Request Type: {event["RequestType"]}')
                      send_cfn_response(event, context, 'SUCCESS')
                      return 'Delete operation completed'

                  elif event['RequestType'] in ['Create', 'Update']:
                      try:
                          codebuild_project_name = event['ResourceProperties']['CodebuildProjectName']
                          logger.info(f'Starting build for project: {codebuild_project_name}')
                          response = codebuild_client.start_build(projectName=codebuild_project_name)
                          logger.info(f'Build started successfully: {response}')
                          send_cfn_response(event, context, 'SUCCESS')
                          return 'Build triggered successfully'
                      except Exception as e:
                          logger.error(f'Error starting build: {str(e)}')
                          logger.error(traceback.format_exc())
                          send_cfn_response(event, context, 'FAILED', f'Error starting build: {str(e)}')
                          return 'Failed to trigger build'
                  else:
                      logger.warning(f'Unsupported request type: {event["RequestType"]}')
                      send_cfn_response(event, context, 'SUCCESS')
                      return f'Unsupported request type: {event["RequestType"]}'
              
              except Exception as e:
                  logger.error(f'Unexpected error: {str(e)}')
                  logger.error(traceback.format_exc())
                  send_cfn_response(event, context, 'FAILED', f'Unexpected error: {str(e)}')
                  return 'Error handling request'

Outputs:
  ClusterRoleArn:
    Description: Cluster Role ARN
    Value: !GetAtt ClusterRole.Arn
  EKSClusterName:
    Description: EKS Cluster Name
    Value: !Ref EKSClusterName
  ArgocdAccessInfo:
    Description: How to access ArgoCD
    Value: Run 'argocd-info' on the VSCode server to get ArgoCD access details
  CloudFormationStack:
    Description: Stack name for reference in scripts
    Value: !Ref AWS::StackName
